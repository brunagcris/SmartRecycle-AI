{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d782f38a",
   "metadata": {},
   "source": [
    "# üóÇÔ∏è **RecycleNet - Classifica√ß√£o de Lixo com CNNs e Attention**\n",
    "\n",
    "## üìä **Projeto Completo com M√©tricas Avan√ßadas e An√°lise**\n",
    "\n",
    "Este notebook implementa o projeto RecycleNet com:\n",
    "- ‚úÖ **M√©tricas completas**: Precis√£o, Recall, F1-Score, Acur√°cia\n",
    "- ‚úÖ **Matriz de confus√£o** e visualiza√ß√µes\n",
    "- ‚úÖ **Gr√°ficos comparativos** para apresenta√ß√£o\n",
    "- ‚úÖ **Teste com webcam** (se dispon√≠vel)\n",
    "- ‚úÖ **Explica√ß√£o detalhada** de todas as m√©tricas\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0765e5ab",
   "metadata": {},
   "source": [
    "## üîß **1. SETUP INICIAL E INSTALA√á√ÉO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc53ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar se estamos no Colab\n",
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"üîó Executando no Google Colab\")\n",
    "    \n",
    "    # Instalar depend√™ncias\n",
    "    !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "    !pip install albumentations==1.3.1\n",
    "    !pip install opencv-python-headless\n",
    "    !pip install scikit-learn seaborn pandas matplotlib\n",
    "    \n",
    "    # Clonar reposit√≥rio\n",
    "    !git clone https://github.com/sangminwoo/RecycleNet.git\n",
    "    %cd RecycleNet\n",
    "    \n",
    "    # Verificar GPU\n",
    "    !nvidia-smi\n",
    "else:\n",
    "    print(\"üíª Executando localmente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfe023c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports essenciais\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "# M√©tricas\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, roc_curve, auc\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Configurar estilo dos gr√°ficos\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ Todos os imports carregados com sucesso!\")\n",
    "print(f\"üî• PyTorch: {torch.__version__}\")\n",
    "print(f\"üñ•Ô∏è  CUDA dispon√≠vel: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"üéÆ GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc8bfd1",
   "metadata": {},
   "source": [
    "## üìä **2. PREPARA√á√ÉO DOS DADOS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686d733a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download do dataset TrashNet\n",
    "if IN_COLAB:\n",
    "    print(\"üì• Baixando dataset TrashNet...\")\n",
    "    !wget -q https://github.com/garythung/trashnet/archive/master.zip\n",
    "    !unzip -q master.zip\n",
    "    !mv trashnet-master/data/dataset-resized ./data/\n",
    "    !rm -rf trashnet-master master.zip\n",
    "    print(\"‚úÖ Dataset baixado e organizado!\")\n",
    "\n",
    "# Verificar estrutura dos dados\n",
    "if os.path.exists('./data/dataset-resized'):\n",
    "    classes = os.listdir('./data/dataset-resized')\n",
    "    print(f\"\\nüìÅ Classes encontradas: {classes}\")\n",
    "    \n",
    "    for class_name in classes:\n",
    "        class_path = f'./data/dataset-resized/{class_name}'\n",
    "        if os.path.isdir(class_path):\n",
    "            count = len([f for f in os.listdir(class_path) if f.endswith(('.jpg', '.jpeg', '.png'))])\n",
    "            print(f\"   ‚Ä¢ {class_name}: {count} imagens\")\n",
    "else:\n",
    "    print(\"‚ùå Dados n√£o encontrados. Verifique o download.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3248b821",
   "metadata": {},
   "source": [
    "## üìà **3. CLASSE PARA M√âTRICAS COMPLETAS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4a232e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricsEvaluator:\n",
    "    \"\"\"\n",
    "    Classe completa para avaliar modelo com todas as m√©tricas necess√°rias\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, class_names=None):\n",
    "        if class_names is None:\n",
    "            self.class_names = ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']\n",
    "        else:\n",
    "            self.class_names = class_names\n",
    "            \n",
    "        self.num_classes = len(self.class_names)\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        \"\"\"Reset das listas para nova avalia√ß√£o\"\"\"\n",
    "        self.all_predictions = []\n",
    "        self.all_targets = []\n",
    "        self.all_probabilities = []\n",
    "    \n",
    "    def update(self, outputs, targets):\n",
    "        \"\"\"Atualiza com batch de predi√ß√µes\"\"\"\n",
    "        if torch.is_tensor(outputs):\n",
    "            outputs = outputs.cpu().detach().numpy()\n",
    "        if torch.is_tensor(targets):\n",
    "            targets = targets.cpu().detach().numpy()\n",
    "            \n",
    "        # Obter probabilidades usando softmax\n",
    "        probabilities = self._softmax(outputs)\n",
    "        predictions = np.argmax(outputs, axis=1)\n",
    "        \n",
    "        self.all_predictions.extend(predictions.tolist())\n",
    "        self.all_targets.extend(targets.tolist())\n",
    "        self.all_probabilities.extend(probabilities.tolist())\n",
    "    \n",
    "    def _softmax(self, x):\n",
    "        \"\"\"Aplica softmax para obter probabilidades\"\"\"\n",
    "        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "        return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "    \n",
    "    def compute_metrics(self):\n",
    "        \"\"\"Calcula todas as m√©tricas\"\"\"\n",
    "        y_true = np.array(self.all_targets)\n",
    "        y_pred = np.array(self.all_predictions)\n",
    "        \n",
    "        metrics = {\n",
    "            'accuracy': accuracy_score(y_true, y_pred),\n",
    "            'precision_macro': precision_score(y_true, y_pred, average='macro', zero_division=0),\n",
    "            'precision_weighted': precision_score(y_true, y_pred, average='weighted', zero_division=0),\n",
    "            'recall_macro': recall_score(y_true, y_pred, average='macro', zero_division=0),\n",
    "            'recall_weighted': recall_score(y_true, y_pred, average='weighted', zero_division=0),\n",
    "            'f1_macro': f1_score(y_true, y_pred, average='macro', zero_division=0),\n",
    "            'f1_weighted': f1_score(y_true, y_pred, average='weighted', zero_division=0),\n",
    "            'precision_per_class': precision_score(y_true, y_pred, average=None, zero_division=0),\n",
    "            'recall_per_class': recall_score(y_true, y_pred, average=None, zero_division=0),\n",
    "            'f1_per_class': f1_score(y_true, y_pred, average=None, zero_division=0),\n",
    "            'confusion_matrix': confusion_matrix(y_true, y_pred)\n",
    "        }\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def plot_confusion_matrix(self, metrics=None, normalize=False):\n",
    "        \"\"\"Plota matriz de confus√£o\"\"\"\n",
    "        if metrics is None:\n",
    "            metrics = self.compute_metrics()\n",
    "            \n",
    "        cm = metrics['confusion_matrix']\n",
    "        \n",
    "        if normalize:\n",
    "            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "            fmt = '.2f'\n",
    "            title = 'Matriz de Confus√£o Normalizada'\n",
    "        else:\n",
    "            fmt = 'd'\n",
    "            title = 'Matriz de Confus√£o'\n",
    "        \n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt=fmt, cmap='Blues',\n",
    "                   xticklabels=self.class_names, yticklabels=self.class_names)\n",
    "        plt.title(title, fontsize=16, fontweight='bold')\n",
    "        plt.xlabel('Classe Predita', fontsize=12)\n",
    "        plt.ylabel('Classe Verdadeira', fontsize=12)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_metrics_by_class(self, metrics=None):\n",
    "        \"\"\"Plota m√©tricas por classe\"\"\"\n",
    "        if metrics is None:\n",
    "            metrics = self.compute_metrics()\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        x = np.arange(len(self.class_names))\n",
    "        width = 0.25\n",
    "        \n",
    "        ax.bar(x - width, metrics['precision_per_class'], width, label='Precis√£o', alpha=0.8)\n",
    "        ax.bar(x, metrics['recall_per_class'], width, label='Recall', alpha=0.8)\n",
    "        ax.bar(x + width, metrics['f1_per_class'], width, label='F1-Score', alpha=0.8)\n",
    "        \n",
    "        ax.set_xlabel('Classes', fontsize=12)\n",
    "        ax.set_ylabel('Score', fontsize=12)\n",
    "        ax.set_title('M√©tricas por Classe', fontsize=16, fontweight='bold')\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(self.class_names, rotation=45)\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_overall_metrics(self, metrics=None):\n",
    "        \"\"\"Plota m√©tricas gerais\"\"\"\n",
    "        if metrics is None:\n",
    "            metrics = self.compute_metrics()\n",
    "        \n",
    "        categories = ['Precis√£o', 'Recall', 'F1-Score']\n",
    "        macro_scores = [metrics['precision_macro'], metrics['recall_macro'], metrics['f1_macro']]\n",
    "        weighted_scores = [metrics['precision_weighted'], metrics['recall_weighted'], metrics['f1_weighted']]\n",
    "        \n",
    "        x = np.arange(len(categories))\n",
    "        width = 0.35\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        bars1 = ax.bar(x - width/2, macro_scores, width, label='M√©dia Macro', alpha=0.8)\n",
    "        bars2 = ax.bar(x + width/2, weighted_scores, width, label='M√©dia Ponderada', alpha=0.8)\n",
    "        \n",
    "        # Linha de acur√°cia\n",
    "        ax.axhline(y=metrics['accuracy'], color='red', linestyle='--', \n",
    "                  label=f'Acur√°cia: {metrics[\"accuracy\"]:.3f}', linewidth=2)\n",
    "        \n",
    "        ax.set_ylabel('Score', fontsize=12)\n",
    "        ax.set_title('M√©tricas Gerais do Modelo', fontsize=16, fontweight='bold')\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(categories)\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.set_ylim(0, 1)\n",
    "        \n",
    "        # Adicionar valores nas barras\n",
    "        for i, (macro, weighted) in enumerate(zip(macro_scores, weighted_scores)):\n",
    "            ax.text(i - width/2, macro + 0.01, f'{macro:.3f}', ha='center', va='bottom')\n",
    "            ax.text(i + width/2, weighted + 0.01, f'{weighted:.3f}', ha='center', va='bottom')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def print_detailed_report(self, metrics=None):\n",
    "        \"\"\"Imprime relat√≥rio detalhado\"\"\"\n",
    "        if metrics is None:\n",
    "            metrics = self.compute_metrics()\n",
    "        \n",
    "        print(\"=\"*60)\n",
    "        print(\"üìä RELAT√ìRIO DETALHADO DE M√âTRICAS\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        print(f\"\\nüéØ M√âTRICAS GERAIS:\")\n",
    "        print(f\"   ‚Ä¢ Acur√°cia: {metrics['accuracy']:.4f} ({metrics['accuracy']*100:.2f}%)\")\n",
    "        print(f\"   ‚Ä¢ F1-Score (Ponderado): {metrics['f1_weighted']:.4f}\")\n",
    "        print(f\"   ‚Ä¢ Precis√£o (Ponderada): {metrics['precision_weighted']:.4f}\")\n",
    "        print(f\"   ‚Ä¢ Recall (Ponderado): {metrics['recall_weighted']:.4f}\")\n",
    "        \n",
    "        print(f\"\\nüìà M√âTRICAS POR CLASSE:\")\n",
    "        for i, class_name in enumerate(self.class_names):\n",
    "            print(f\"   ‚Ä¢ {class_name.upper()}:\")\n",
    "            print(f\"     - Precis√£o: {metrics['precision_per_class'][i]:.4f}\")\n",
    "            print(f\"     - Recall: {metrics['recall_per_class'][i]:.4f}\")\n",
    "            print(f\"     - F1-Score: {metrics['f1_per_class'][i]:.4f}\")\n",
    "        \n",
    "        return metrics\n",
    "\n",
    "print(\"‚úÖ Classe MetricsEvaluator criada com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65391352",
   "metadata": {},
   "source": [
    "## üìö **4. GUIA DE INTERPRETA√á√ÉO DAS M√âTRICAS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5558a121",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_metrics():\n",
    "    \"\"\"\n",
    "    Explica todas as m√©tricas para voc√™ entender os resultados\n",
    "    \"\"\"\n",
    "    print(\"üìö GUIA COMPLETO DE INTERPRETA√á√ÉO DAS M√âTRICAS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    explanations = {\n",
    "        \"üéØ ACUR√ÅCIA\": {\n",
    "            \"O que √©\": \"Propor√ß√£o de predi√ß√µes corretas sobre o total\",\n",
    "            \"F√≥rmula\": \"(VP + VN) / (VP + VN + FP + FN)\",\n",
    "            \"Como interpretar\": \"Quanto MAIOR, MELHOR. Ideal > 90%\",\n",
    "            \"Cuidado\": \"Pode enganar em datasets desbalanceados\"\n",
    "        },\n",
    "        \n",
    "        \"üîç PRECIS√ÉO\": {\n",
    "            \"O que √©\": \"Das predi√ß√µes positivas, quantas est√£o corretas\",\n",
    "            \"F√≥rmula\": \"VP / (VP + FP)\",\n",
    "            \"Como interpretar\": \"Quanto MAIOR, MELHOR. Indica confiabilidade\",\n",
    "            \"Quando importante\": \"Quando falsos positivos s√£o caros\"\n",
    "        },\n",
    "        \n",
    "        \"üé£ RECALL (SENSIBILIDADE)\": {\n",
    "            \"O que √©\": \"Dos casos reais, quantos foram encontrados\",\n",
    "            \"F√≥rmula\": \"VP / (VP + FN)\",\n",
    "            \"Como interpretar\": \"Quanto MAIOR, MELHOR. Indica cobertura\",\n",
    "            \"Quando importante\": \"Quando falsos negativos s√£o caros\"\n",
    "        },\n",
    "        \n",
    "        \"‚öñÔ∏è F1-SCORE\": {\n",
    "            \"O que √©\": \"M√©dia harm√¥nica entre precis√£o e recall\",\n",
    "            \"F√≥rmula\": \"2 √ó (Precis√£o √ó Recall) / (Precis√£o + Recall)\",\n",
    "            \"Como interpretar\": \"Quanto MAIOR, MELHOR. Equilibra precis√£o e recall\",\n",
    "            \"Vantagem\": \"Melhor m√©trica para datasets desbalanceados\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    for metric, info in explanations.items():\n",
    "        print(f\"\\n{metric}\")\n",
    "        print(\"-\" * 40)\n",
    "        for key, value in info.items():\n",
    "            print(f\"  ‚Ä¢ {key}: {value}\")\n",
    "    \n",
    "    print(\"\\nüîÑ TIPOS DE M√âDIA:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(\"  ‚Ä¢ MACRO: M√©dia simples (todas as classes t√™m peso igual)\")\n",
    "    print(\"  ‚Ä¢ PONDERADA: M√©dia ponderada (classes com mais amostras t√™m mais peso)\")\n",
    "    print(\"  ‚Ä¢ MICRO: Considera total global de VP, FP, FN\")\n",
    "    \n",
    "    print(\"\\nüìä COMO INTERPRETAR SEUS RESULTADOS:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(\"  üü¢ Acur√°cia > 90%: EXCELENTE desempenho\")\n",
    "    print(\"  üîµ Acur√°cia 80-90%: BOM desempenho\")\n",
    "    print(\"  üü° Acur√°cia 70-80%: MODERADO (pode melhorar)\")\n",
    "    print(\"  üî¥ Acur√°cia < 70%: PRECISA MELHORAR\")\n",
    "    \n",
    "    print(\"\\nüí° DICAS PARA SUA APRESENTA√á√ÉO:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(\"  1. SEMPRE mostre a matriz de confus√£o\")\n",
    "    print(\"  2. Compare m√©tricas macro vs ponderadas\")\n",
    "    print(\"  3. Analise quais classes t√™m mais erros\")\n",
    "    print(\"  4. Explique por que F1-Score √© importante aqui\")\n",
    "    print(\"  5. Mostre gr√°ficos comparativos entre modelos\")\n",
    "\n",
    "# Executar explica√ß√£o\n",
    "explain_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879ea0f3",
   "metadata": {},
   "source": [
    "## ü§ñ **5. CARREGAMENTO E AVALIA√á√ÉO DO MODELO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636f43de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simula√ß√£o de dados para demonstra√ß√£o (substitua pelo seu modelo real)\n",
    "def simulate_model_predictions(num_samples=1000, num_classes=6):\n",
    "    \"\"\"\n",
    "    Simula predi√ß√µes de um modelo para demonstra√ß√£o\n",
    "    Substitua esta fun√ß√£o pelo seu modelo real\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Simular logits (sa√≠da do modelo antes do softmax)\n",
    "    logits = np.random.randn(num_samples, num_classes)\n",
    "    \n",
    "    # Simular targets verdadeiros\n",
    "    targets = np.random.randint(0, num_classes, num_samples)\n",
    "    \n",
    "    # Adicionar um pouco de \"intelig√™ncia\" ao modelo simulado\n",
    "    # Fazer com que a classe correta tenha maior probabilidade\n",
    "    for i in range(num_samples):\n",
    "        if np.random.random() > 0.2:  # 80% de chance de acertar\n",
    "            logits[i, targets[i]] += 2.0  # Aumentar logit da classe correta\n",
    "    \n",
    "    return logits, targets\n",
    "\n",
    "print(\"üé≤ Gerando dados simulados para demonstra√ß√£o...\")\n",
    "simulated_logits, simulated_targets = simulate_model_predictions()\n",
    "\n",
    "print(f\"üìä Dados simulados: {simulated_logits.shape[0]} amostras, {simulated_logits.shape[1]} classes\")\n",
    "print(\"‚úÖ Para usar seu modelo real, substitua esta se√ß√£o pelo carregamento do modelo treinado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c792d9",
   "metadata": {},
   "source": [
    "## üìä **6. AVALIA√á√ÉO COMPLETA COM TODAS AS M√âTRICAS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfad4756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar avaliador de m√©tricas\n",
    "class_names = ['Papel√£o', 'Vidro', 'Metal', 'Papel', 'Pl√°stico', 'Lixo']\n",
    "evaluator = MetricsEvaluator(class_names=class_names)\n",
    "\n",
    "print(\"üîÑ Executando avalia√ß√£o completa...\")\n",
    "\n",
    "# Atualizar com predi√ß√µes (substitua pelos dados reais do seu modelo)\n",
    "evaluator.update(simulated_logits, simulated_targets)\n",
    "\n",
    "# Calcular todas as m√©tricas\n",
    "metrics = evaluator.compute_metrics()\n",
    "\n",
    "# Imprimir relat√≥rio detalhado\n",
    "final_metrics = evaluator.print_detailed_report(metrics)\n",
    "\n",
    "print(\"\\n‚úÖ Avalia√ß√£o completa finalizada!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7076b75d",
   "metadata": {},
   "source": [
    "## üìà **7. VISUALIZA√á√ïES PARA SUA APRESENTA√á√ÉO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db125c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Matriz de Confus√£o\n",
    "print(\"üìä 1. MATRIZ DE CONFUS√ÉO\")\n",
    "evaluator.plot_confusion_matrix(metrics, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5354bb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Matriz de Confus√£o Normalizada\n",
    "print(\"üìä 2. MATRIZ DE CONFUS√ÉO NORMALIZADA\")\n",
    "evaluator.plot_confusion_matrix(metrics, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da12ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. M√©tricas por Classe\n",
    "print(\"üìä 3. M√âTRICAS POR CLASSE\")\n",
    "evaluator.plot_metrics_by_class(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7076eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. M√©tricas Gerais\n",
    "print(\"üìä 4. M√âTRICAS GERAIS\")\n",
    "evaluator.plot_overall_metrics(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21557f64",
   "metadata": {},
   "source": [
    "## üîç **8. GR√ÅFICO COMPARATIVO ENTRE MODELOS**\n",
    "Este gr√°fico √© PERFEITO para sua apresenta√ß√£o!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851af7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_comparison():\n",
    "    \"\"\"\n",
    "    Gr√°fico comparativo baseado nos resultados do paper original\n",
    "    Perfeito para apresenta√ß√£o!\n",
    "    \"\"\"\n",
    "    # Dados do paper original\n",
    "    models = ['ResNet18\\n(Baseline)', 'ResNet18\\n+ SE', 'ResNet18\\n+ CBAM', 'ResNet18\\n+ RecycleNet']\n",
    "    accuracies = [90.023, 87.703, 79.814, 93.039]\n",
    "    parameters = [11.18, 11.27, 11.27, 11.24]\n",
    "    \n",
    "    # Criar subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Gr√°fico 1: Acur√°cia\n",
    "    colors = ['lightblue', 'orange', 'lightcoral', 'lightgreen']\n",
    "    bars1 = ax1.bar(models, accuracies, color=colors, alpha=0.8, edgecolor='black')\n",
    "    ax1.set_ylabel('Acur√°cia (%)', fontsize=12)\n",
    "    ax1.set_title('Compara√ß√£o de Acur√°cia entre Modelos', fontsize=14, fontweight='bold')\n",
    "    ax1.set_ylim(70, 95)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Adicionar valores nas barras\n",
    "    for bar, acc in zip(bars1, accuracies):\n",
    "        height = bar.get_height()\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
    "                f'{acc:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # Gr√°fico 2: Acur√°cia vs Par√¢metros\n",
    "    ax2.scatter(parameters, accuracies, c=colors, s=200, alpha=0.8, edgecolors='black')\n",
    "    for i, model in enumerate(models):\n",
    "        ax2.annotate(model.replace('\\n', ' '), (parameters[i], accuracies[i]), \n",
    "                    xytext=(5, 5), textcoords='offset points', fontsize=10)\n",
    "    \n",
    "    ax2.set_xlabel('Par√¢metros (M)', fontsize=12)\n",
    "    ax2.set_ylabel('Acur√°cia (%)', fontsize=12)\n",
    "    ax2.set_title('Efici√™ncia: Acur√°cia vs N√∫mero de Par√¢metros', fontsize=14, fontweight='bold')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Destacar o melhor resultado\n",
    "    best_idx = np.argmax(accuracies)\n",
    "    print(f\"üèÜ MELHOR MODELO: {models[best_idx]}\")\n",
    "    print(f\"   ‚Ä¢ Acur√°cia: {accuracies[best_idx]:.3f}%\")\n",
    "    print(f\"   ‚Ä¢ Par√¢metros: {parameters[best_idx]:.2f}M\")\n",
    "    print(f\"   ‚Ä¢ Melhoria sobre baseline: +{accuracies[best_idx] - accuracies[0]:.3f}%\")\n",
    "\n",
    "plot_model_comparison()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf6d836",
   "metadata": {},
   "source": [
    "## üìπ **9. TESTE COM WEBCAM (SE DISPON√çVEL)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728df53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_webcam_availability():\n",
    "    \"\"\"\n",
    "    Testa se a webcam est√° dispon√≠vel\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # No Colab, isso geralmente n√£o funcionar√°\n",
    "        if IN_COLAB:\n",
    "            print(\"üì± NOTA: Webcam n√£o dispon√≠vel no Google Colab\")\n",
    "            print(\"üí° Para testar webcam:\")\n",
    "            print(\"   1. Execute o c√≥digo localmente\")\n",
    "            print(\"   2. Ou use o c√≥digo de webcam que forneci\")\n",
    "            print(\"   3. Ou fa√ßa upload de imagens para teste\")\n",
    "            return False\n",
    "        else:\n",
    "            cap = cv2.VideoCapture(0)\n",
    "            if cap.isOpened():\n",
    "                print(\"‚úÖ Webcam dispon√≠vel!\")\n",
    "                cap.release()\n",
    "                return True\n",
    "            else:\n",
    "                print(\"‚ùå Webcam n√£o encontrada\")\n",
    "                return False\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro ao acessar webcam: {e}\")\n",
    "        return False\n",
    "\n",
    "# Teste de disponibilidade da webcam\n",
    "webcam_available = test_webcam_availability()\n",
    "\n",
    "if not webcam_available:\n",
    "    print(\"\\nüîß INSTRU√á√ïES PARA USAR WEBCAM LOCALMENTE:\")\n",
    "    print(\"   1. Baixe o arquivo 'webcam_enhanced.py' do reposit√≥rio\")\n",
    "    print(\"   2. Execute: python webcam_enhanced.py --resume save/model_best.pth.tar\")\n",
    "    print(\"   3. Use SPACE para capturar e classificar\")\n",
    "    print(\"   4. Use P para mostrar todas as probabilidades\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09d9328",
   "metadata": {},
   "source": [
    "## üì§ **10. TESTE COM UPLOAD DE IMAGEM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c08831",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_image_prediction(image_path=None):\n",
    "    \"\"\"\n",
    "    Simula predi√ß√£o em uma imagem\n",
    "    Substitua pela sua fun√ß√£o real de predi√ß√£o\n",
    "    \"\"\"\n",
    "    # Simula√ß√£o - substitua pelo seu modelo real\n",
    "    class_names = ['Papel√£o', 'Vidro', 'Metal', 'Papel', 'Pl√°stico', 'Lixo']\n",
    "    \n",
    "    # Predi√ß√£o simulada\n",
    "    predicted_class = np.random.choice(len(class_names))\n",
    "    confidence = np.random.uniform(0.7, 0.95)\n",
    "    \n",
    "    # Probabilidades simuladas\n",
    "    probs = np.random.random(len(class_names))\n",
    "    probs[predicted_class] = confidence\n",
    "    probs = probs / probs.sum()  # Normalizar\n",
    "    \n",
    "    return {\n",
    "        'predicted_class': predicted_class,\n",
    "        'predicted_name': class_names[predicted_class],\n",
    "        'confidence': confidence,\n",
    "        'probabilities': probs\n",
    "    }\n",
    "\n",
    "# Interface para upload (apenas no Colab)\n",
    "if IN_COLAB:\n",
    "    from google.colab import files\n",
    "    print(\"üì§ Upload uma imagem para testar a classifica√ß√£o:\")\n",
    "    \n",
    "    try:\n",
    "        uploaded = files.upload()\n",
    "        \n",
    "        for filename in uploaded.keys():\n",
    "            print(f\"\\nüîç Processando {filename}...\")\n",
    "            \n",
    "            # Carregar e mostrar imagem\n",
    "            img = Image.open(filename)\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.imshow(img)\n",
    "            plt.title(f'Imagem: {filename}', fontsize=14)\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "            \n",
    "            # Fazer predi√ß√£o (simulada)\n",
    "            prediction = simulate_image_prediction(filename)\n",
    "            \n",
    "            print(f\"üìä RESULTADO DA CLASSIFICA√á√ÉO:\")\n",
    "            print(f\"   üéØ Classe predita: {prediction['predicted_name']}\")\n",
    "            print(f\"   üî¢ Confian√ßa: {prediction['confidence']:.3f} ({prediction['confidence']*100:.1f}%)\")\n",
    "            \n",
    "            print(f\"\\nüìà Todas as probabilidades:\")\n",
    "            class_names = ['Papel√£o', 'Vidro', 'Metal', 'Papel', 'Pl√°stico', 'Lixo']\n",
    "            for name, prob in zip(class_names, prediction['probabilities']):\n",
    "                print(f\"   ‚Ä¢ {name}: {prob:.3f} ({prob*100:.1f}%)\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Nenhuma imagem foi carregada ou erro: {e}\")\n",
    "else:\n",
    "    print(\"üíª Para testar localmente, use o arquivo webcam_enhanced.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bb132d",
   "metadata": {},
   "source": [
    "## üìã **11. RESUMO FINAL E DICAS PARA APRESENTA√á√ÉO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a4be10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_presentation_summary(metrics):\n",
    "    \"\"\"\n",
    "    Gera resumo executivo para apresenta√ß√£o\n",
    "    \"\"\"\n",
    "    print(\"üéØ RESUMO EXECUTIVO PARA SUA APRESENTA√á√ÉO\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(f\"\\nüìä PRINCIPAIS RESULTADOS:\")\n",
    "    print(f\"   ‚Ä¢ Acur√°cia geral: {metrics['accuracy']:.1%}\")\n",
    "    print(f\"   ‚Ä¢ F1-Score ponderado: {metrics['f1_weighted']:.3f}\")\n",
    "    print(f\"   ‚Ä¢ Melhor classe: {np.argmax(metrics['f1_per_class'])} (F1: {np.max(metrics['f1_per_class']):.3f})\")\n",
    "    print(f\"   ‚Ä¢ Classe com mais dificuldade: {np.argmin(metrics['f1_per_class'])} (F1: {np.min(metrics['f1_per_class']):.3f})\")\n",
    "    \n",
    "    print(f\"\\nüéØ PONTOS PRINCIPAIS PARA APRESENTAR:\")\n",
    "    print(f\"   1. O modelo RecycleNet supera m√©todos de aten√ß√£o tradicionais\")\n",
    "    print(f\"   2. Transfer learning √© CRUCIAL (melhoria de ~20% vs. scratch)\")\n",
    "    print(f\"   3. Mecanismo de aten√ß√£o melhora foco em caracter√≠sticas relevantes\")\n",
    "    print(f\"   4. Dataset pequeno (2527 imagens) mas resultados competitivos\")\n",
    "    print(f\"   5. Aplica√ß√£o pr√°tica importante para sustentabilidade\")\n",
    "    \n",
    "    print(f\"\\nüìà GR√ÅFICOS ESSENCIAIS PARA MOSTRAR:\")\n",
    "    print(f\"   ‚úÖ Matriz de confus√£o (mostra onde o modelo erra)\")\n",
    "    print(f\"   ‚úÖ Compara√ß√£o entre modelos (ResNet vs. RecycleNet)\")\n",
    "    print(f\"   ‚úÖ M√©tricas por classe (identifica classes problem√°ticas)\")\n",
    "    print(f\"   ‚úÖ F1-Score (melhor m√©trica para este problema)\")\n",
    "    \n",
    "    print(f\"\\nüí° DICAS DE APRESENTA√á√ÉO:\")\n",
    "    print(f\"   üé§ Comece explicando o PROBLEMA (classifica√ß√£o de lixo)\")\n",
    "    print(f\"   üé§ Mostre a SOLU√á√ÉO (CNN + Attention + Transfer Learning)\")\n",
    "    print(f\"   üé§ Apresente os RESULTADOS (use os gr√°ficos deste notebook)\")\n",
    "    print(f\"   üé§ Discuta LIMITA√á√ïES (dataset pequeno, classes desbalanceadas)\")\n",
    "    print(f\"   üé§ Conclua com APLICA√á√ïES (sustentabilidade, automa√ß√£o)\")\n",
    "    \n",
    "    print(f\"\\nüîç ASPECTOS T√âCNICOS IMPORTANTES:\")\n",
    "    print(f\"   ‚Ä¢ Backbone: ResNet (comprovado e eficiente)\")\n",
    "    print(f\"   ‚Ä¢ Attention: Foca em caracter√≠sticas relevantes\")\n",
    "    print(f\"   ‚Ä¢ Transfer Learning: Aproveita conhecimento do ImageNet\")\n",
    "    print(f\"   ‚Ä¢ Data Augmentation: Aumenta variabilidade do dataset\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Gerar resumo final\n",
    "generate_presentation_summary(final_metrics)\n",
    "\n",
    "print(\"\\nüéâ PARAB√âNS! Seu projeto est√° completo!\")\n",
    "print(\"üìö Voc√™ agora tem todas as m√©tricas e visualiza√ß√µes necess√°rias\")\n",
    "print(\"üéØ Use este notebook como base para sua apresenta√ß√£o\")\n",
    "print(\"‚ú® Boa sorte na apresenta√ß√£o!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd1cd49",
   "metadata": {},
   "source": [
    "## üöÄ **PR√ìXIMOS PASSOS**\n",
    "\n",
    "### Para usar com seu modelo real:\n",
    "\n",
    "1. **Substitua a se√ß√£o de simula√ß√£o** pelos dados reais do seu modelo\n",
    "2. **Carregue o modelo treinado** usando `torch.load()`\n",
    "3. **Execute predi√ß√µes reais** no dataset de teste\n",
    "4. **Use este c√≥digo** para gerar todas as m√©tricas\n",
    "\n",
    "### Para testar webcam localmente:\n",
    "\n",
    "```python\n",
    "python webcam_enhanced.py --resume save/model_best.pth.tar --use_att --att_mode ours\n",
    "```\n",
    "\n",
    "### Para treinar o modelo:\n",
    "\n",
    "```python\n",
    "# Sem aten√ß√£o\n",
    "python main.py --gpu 0 --arch resnet18_base\n",
    "\n",
    "# Com aten√ß√£o RecycleNet\n",
    "python main.py --gpu 0 --arch resnet18_base --use_att --att_mode ours\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üìö **RECURSOS ADICIONAIS**\n",
    "\n",
    "- **Paper original**: [RecycleNet GitHub](https://github.com/sangminwoo/RecycleNet)\n",
    "- **Dataset**: [TrashNet](https://github.com/garythung/trashnet)\n",
    "- **M√©tricas**: [Scikit-learn Documentation](https://scikit-learn.org/stable/modules/model_evaluation.html)\n",
    "\n",
    "---\n",
    "\n",
    "**üéØ Projeto desenvolvido para Ci√™ncia da Computa√ß√£o - Reconhecimento de Padr√µes**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
