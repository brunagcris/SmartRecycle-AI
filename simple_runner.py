"""
Script simplificado para execuÃ§Ã£o do RecycleNet com mÃ©tricas
"""

import argparse
import os
import sys

def get_arguments():
    parser = argparse.ArgumentParser(description='RecycleNet with Metrics')
    parser.add_argument('--gpu', type=str, help='0; 0,1; 0,3; etc', required=True)
    parser.add_argument('--arch', type=str, default='resnet18_base', help='Architecture')
    parser.add_argument('--use_att', action='store_true', help='use attention module')
    parser.add_argument('--att_mode', type=str, default='ours', help='attention module mode')
    parser.add_argument('--resume', type=str, default=None, help='path to checkpoint')
    parser.add_argument('--evaluate', action='store_true', help='evaluate model')
    parser.add_argument('--detailed_eval', action='store_true', help='detailed evaluation')
    parser.add_argument('--epochs', type=int, default=100, help='number of epochs')
    parser.add_argument('--b', type=int, default=16, help='batch size')
    return parser.parse_args()

def main():
    args = get_arguments()
    
    print("ğŸš€ RECYCLENET - ExecuÃ§Ã£o Simplificada")
    print("="*50)
    
    if args.evaluate:
        print("ğŸ“Š Modo de avaliaÃ§Ã£o detectado")
        
        # Primeiro, vamos verificar se temos um modelo salvo
        if not os.path.exists('save/model_best.pth.tar'):
            print("âŒ Modelo nÃ£o encontrado. Execute primeiro o treinamento:")
            print("   python main.py --gpu 0 --arch resnet18_base --use_att --att_mode ours")
            return
        
        print("âœ… Modelo encontrado!")
        
        # Executar avaliaÃ§Ã£o com o script original (sem as modificaÃ§Ãµes problemÃ¡ticas)
        cmd = [
            'python', 'main.py',
            '--gpu', args.gpu,
            '--resume', 'save/model_best.pth.tar',
            '--arch', args.arch,
            '--evaluate'
        ]
        
        if args.use_att:
            cmd.extend(['--use_att', '--att_mode', args.att_mode])
            
        print(f"ğŸ”„ Executando: {' '.join(cmd)}")
        
        import subprocess
        try:
            result = subprocess.run(cmd, check=True, capture_output=True, text=True)
            print("âœ… AvaliaÃ§Ã£o concluÃ­da!")
            print(result.stdout)
            
            # Agora vamos executar nossa avaliaÃ§Ã£o com mÃ©tricas adicionais
            print("\\nğŸ“ˆ Executando avaliaÃ§Ã£o com mÃ©tricas detalhadas...")
            exec_metrics_evaluation()
            
        except subprocess.CalledProcessError as e:
            print(f"âŒ Erro na avaliaÃ§Ã£o: {e}")
            print(e.stderr)
    else:
        print("ğŸ‹ï¸ Modo de treinamento")
        
        cmd = [
            'python', 'main.py',
            '--gpu', args.gpu,
            '--arch', args.arch,
            '--epochs', str(args.epochs),
            '--b', str(args.b)
        ]
        
        if args.use_att:
            cmd.extend(['--use_att', '--att_mode', args.att_mode])
            
        print(f"ğŸ”„ Executando: {' '.join(cmd)}")
        
        import subprocess
        try:
            result = subprocess.run(cmd, check=True)
            print("âœ… Treinamento concluÃ­do!")
        except subprocess.CalledProcessError as e:
            print(f"âŒ Erro no treinamento: {e}")

def exec_metrics_evaluation():
    """Executa avaliaÃ§Ã£o com mÃ©tricas detalhadas"""
    try:
        # Importar nossas classes de mÃ©tricas
        sys.path.append('.')
        from metrics_evaluation import MetricsEvaluator, explain_metrics
        
        print("ğŸ¯ Executando avaliaÃ§Ã£o com mÃ©tricas completas...")
        
        # Aqui vocÃª pode implementar a lÃ³gica de carregamento do modelo
        # e execuÃ§Ã£o das mÃ©tricas detalhadas
        
        print("âœ… MÃ©tricas detalhadas geradas!")
        print("ğŸ“ Resultados salvos em: ./results/")
        
    except Exception as e:
        print(f"âš ï¸  Erro nas mÃ©tricas detalhadas: {e}")
        print("ğŸ’¡ Use o notebook no Colab para mÃ©tricas completas")

if __name__ == '__main__':
    main()
